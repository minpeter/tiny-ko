{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01fd90ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/minpeter/github.com/minpeter/mirco-ko-llama/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e500d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 18/18 [00:00<00:00, 42.70files/s]\n",
      "Generating train split: 100%|██████████| 1284879/1284879 [00:19<00:00, 65731.50 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'source', 'token_count', '__index_level_0__'],\n",
       "    num_rows: 1284879\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = datasets.load_dataset('HAERAE-HUB/KOREAN-WEBTEXT', split='train')\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7282d01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 102/102 [00:00<00:00, 311.13files/s]\n",
      "Generating train split: 100%|██████████| 2261464/2261464 [01:46<00:00, 21276.61 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2261464\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = datasets.load_dataset('blueapple8259/c4-ko-cleaned-2', split='train')\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026239db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 1552370/1552370 [00:12<00:00, 127132.02 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', '__index_level_0__'],\n",
       "    num_rows: 1552370\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3 = datasets.load_dataset('HAERAE-HUB/KOREAN-SyntheticText-1.5B', split='train')\n",
    "dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b4797b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 1735255/1735255 [00:11<00:00, 149967.43 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'score'],\n",
       "    num_rows: 1735255\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maywell/korean_textbooks 데이터셋에서 분류기로 3점 이상의 데이터만 수집\n",
    "dataset4 = datasets.load_dataset(\"devngho/korean-textbooks-edu\", name=\"scored_over_3\", split=\"train\")\n",
    "dataset4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbf9ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 25/25 [00:06<00:00,  4.15files/s]\n",
      "Generating train split: 100%|██████████| 436660/436660 [00:00<00:00, 548302.28 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['category', 'begin', 'end', 'text', 'num_agree', 'petition_idx', 'status', 'title'],\n",
       "    num_rows: 436660\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 청와대 국민청원\n",
    "dataset5 = datasets.load_dataset(\"heegyu/korean-petitions\", split=\"train\")\n",
    "# dataset5에서 content 필드명을 text로 변경\n",
    "dataset5 = dataset5.rename_column(\"content\", \"text\")\n",
    "dataset5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07771364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'source', 'token_count', '__index_level_0__', 'score', 'category', 'begin', 'end', 'num_agree', 'petition_idx', 'status', 'title'],\n",
       "    num_rows: 7270628\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "combined_dataset = concatenate_datasets([dataset1, dataset2, dataset3, dataset4, dataset5])\n",
    "combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. 텍스트 정제 및 정규화를 시작합니다... (.map)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=42):   2%|▏         | 130695/7270628 [00:06<03:27, 34431.13 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  10%|█         | 737374/7270628 [00:23<03:10, 34333.34 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  11%|█         | 804897/7270628 [00:25<03:01, 35652.52 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  12%|█▏        | 873140/7270628 [00:27<03:07, 34127.11 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  18%|█▊        | 1316417/7270628 [00:40<02:52, 34613.31 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  27%|██▋       | 1976413/7270628 [00:58<02:25, 36351.63 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  31%|███       | 2218941/7270628 [01:05<02:21, 35792.27 examples/s]/data/minpeter/github.com/minpeter/mirco-ko-llama/.venv/lib/python3.13/site-packages/bs4/__init__.py:473: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  self._feed()\n",
      "Map (num_proc=42):  32%|███▏      | 2345025/7270628 [01:09<02:18, 35484.76 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  40%|███▉      | 2881324/7270628 [01:24<02:03, 35512.00 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  44%|████▍     | 3199175/7270628 [01:33<02:07, 31889.81 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  55%|█████▌    | 4006984/7270628 [01:58<01:39, 32706.89 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  61%|██████▏   | 4456763/7270628 [02:12<01:26, 32710.47 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  65%|██████▍   | 4716847/7270628 [02:20<01:23, 30727.08 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  68%|██████▊   | 4971296/7270628 [02:28<01:18, 29323.01 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  70%|██████▉   | 5067563/7270628 [02:31<01:10, 31254.41 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  72%|███████▏  | 5213682/7270628 [02:36<01:08, 30083.33 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  75%|███████▍  | 5433818/7270628 [02:43<00:59, 30784.06 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  76%|███████▌  | 5495426/7270628 [02:45<00:58, 30605.36 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  76%|███████▋  | 5545928/7270628 [02:47<00:55, 31302.62 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  78%|███████▊  | 5658678/7270628 [02:51<00:53, 30326.46 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  78%|███████▊  | 5695225/7270628 [02:52<00:51, 30449.86 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  83%|████████▎ | 6035955/7270628 [03:03<00:40, 30573.71 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42):  94%|█████████▍| 6854906/7270628 [03:32<00:18, 22787.50 examples/s]/tmp/ipykernel_345646/1048091155.py:18: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Map (num_proc=42): 100%|██████████| 7270628/7270628 [10:16<00:00, 11798.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 텍스트 정제 완료\n",
      "정제 후 데이터셋 정보: Dataset({\n",
      "    features: ['text', 'source', 'token_count', '__index_level_0__', 'score', 'category', 'begin', 'end', 'num_agree', 'petition_idx', 'status', 'title'],\n",
      "    num_rows: 7270628\n",
      "})\n",
      "\n",
      "3. 품질 및 중복 필터링을 시작합니다... (.filter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:  13%|█▎        | 957000/7270628 [00:29<02:29, 42251.66 examples/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import hanja\n",
    "from bs4 import MarkupResemblesLocatorWarning\n",
    "import warnings\n",
    "\n",
    "# =============================================================================\n",
    "# PART 1: 모든 전처리 함수 정의\n",
    "# =============================================================================\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    논의된 모든 텍스트 정제 및 정규화 규칙을 순서대로 적용하는 함수\n",
    "    \"\"\"\n",
    "    # 1-1. HTML 태그 제거\n",
    "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # 1-2. URL 및 이메일 주소 제거\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '[URL_PLACEHOLDER]', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '[EMAIL_PLACEHOLDER]', text)\n",
    "    \n",
    "    # 1-3. 한자를 한글로 변환\n",
    "    text = hanja.translate(text, 'substitution')\n",
    "    # 이후 단어(단어), 단어 (단어) 와 같이 단어 뒤에 바로 같은 단어가 괄호로 감싸져 오는 경우, 뒤에 (단어) 를 제거하도록 필터 추가\n",
    "    text = re.sub(r'(\\S+)\\s+\\(\\1\\)', r'\\1', text)\n",
    "\n",
    "    # 1-4. 불필요한 특수문자 제거 (한글, 영어, 숫자, 아스키코드 기호는 모두 허용)\n",
    "    text = re.sub(r'[^ ㄱ-ㅣ가-힣a-zA-Z0-9!\"#$%&\\'()*+,\\-./:;<=>?@[\\\\\\]^_`{|}~]', '', text)\n",
    "    \n",
    "    # 1-5. 반복 문자 처리 (ㅋㅋ, ㅎㅎ 등)\n",
    "    text = re.sub(r'([ㄱ-ㅎㅏ-ㅣ])\\1{2,}', r'\\1\\1', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 중복 제거를 위한 전역 세트(set) 선언\n",
    "seen_texts = set()\n",
    "\n",
    "def is_high_quality_and_unique(example):\n",
    "    \"\"\"\n",
    "    품질 필터링(길이)과 중복 제거를 동시에 수행하는 함수\n",
    "    \"\"\"\n",
    "    text = example['text']\n",
    "    \n",
    "    # 2-1. 길이 필터링: 텍스트 길이가 100글자 미만이면 탈락\n",
    "    if len(text) < 100:\n",
    "        return False\n",
    "    \n",
    "    # 2-2. 중복 필터링: 이미 등장한 텍스트면 탈락\n",
    "    if text in seen_texts:\n",
    "        return False\n",
    "    \n",
    "    # 모든 필터를 통과한 경우, seen_texts에 추가하고 통과 처리\n",
    "    seen_texts.add(text)\n",
    "    return True\n",
    "\n",
    "\n",
    "max_num_proc= int(os.cpu_count() / 3)\n",
    "\n",
    "\n",
    "print(\"\\n2. 텍스트 정제 및 정규화를 시작합니다... (.map)\")\n",
    "cleaned_dataset = combined_dataset.map(\n",
    "    lambda example: {'text': clean_text(example['text'])},\n",
    "    num_proc=max_num_proc,\n",
    ")\n",
    "print(\"✅ 텍스트 정제 완료\")\n",
    "print(\"정제 후 데이터셋 정보:\", cleaned_dataset)\n",
    "\n",
    "# --- 3. 품질 및 중복 필터링 (.filter) ---\n",
    "# 정제된 텍스트를 기준으로 길이 필터링 및 중복 제거를 수행합니다.\n",
    "print(\"\\n3. 품질 및 중복 필터링을 시작합니다... (.filter)\")\n",
    "final_dataset = cleaned_dataset.filter(\n",
    "    is_high_quality_and_unique,\n",
    "    num_proc=1 # 'seen_texts' 세트는 전역 변수이므로 다중 처리(num_proc > 1) 시 충돌할 수 있습니다.\n",
    "                # 대용량 데이터 처리 시에는 다른 중복 제거 방식이 필요할 수 있습니다.\n",
    ")\n",
    "print(\"✅ 필터링 완료\")\n",
    "print(\"\\n--- 최종 결과 ---\")\n",
    "print(\"최종 데이터셋 정보:\", final_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 컬럼만 남기고 나머지 컬럼 제거\n",
    "columns_to_remove = [col for col in cleaned_dataset.column_names if col != \"text\"]\n",
    "text_only_dataset = cleaned_dataset.remove_columns(columns_to_remove)\n",
    "text_only_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396a9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset = text_only_dataset.shuffle(seed=5768112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b73b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset.push_to_hub(\"minpeter/pretrain-korean-dedup\", split=\"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
