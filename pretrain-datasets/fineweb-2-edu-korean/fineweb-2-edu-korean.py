import os
import torch
from typing import Dict, Any, List
from functools import partial # functools.partial ì„í¬íŠ¸

from datatrove.data import Document, DocumentsPipeline
from datatrove.executor.local import LocalPipelineExecutor
from datatrove.pipeline.base import PipelineStep
from datatrove.pipeline.readers import ParquetReader
from datatrove.pipeline.writers import HuggingFaceDatasetWriter
from datatrove.utils.batching import batched
from transformers import AutoTokenizer, AutoModelForSequenceClassification


# torch memory cleanup
torch.cuda.empty_cache()

if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8:
    print("TF32 ì‚¬ìš© ê°€ëŠ¥. í–‰ë ¬ ê³± ì •ë°€ë„ ì„¤ì • ì¤‘...")
    torch.set_float32_matmul_precision('high')

# 1. ë¶„ë¥˜ê¸° ë¸”ë¡ (ê¸°ì¡´ê³¼ ë™ì¼)
class EduScoreClassifier(PipelineStep):
    """
    'devngho/ko_edu_classifier_v2_nlpai-lab_KoE5' ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬
    í…ìŠ¤íŠ¸ì˜ êµìœ¡ì  ê°€ì¹˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    ëª¨ë¸ì˜ ì›ì‹œ logit ì¶œë ¥ì„ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ íšŒê·€ ì ìˆ˜ë¥¼ ì–»ìŠµë‹ˆë‹¤.
    """
    type = "ğŸ§‘â€ğŸ« - CLASSIFIER"
    name = "Ko-EDU Score Classifier"

    def __init__(
        self,
        model_name: str = "devngho/ko_edu_classifier_v2_nlpai-lab_KoE5",
        batch_size: int = 32,
    ):
        super().__init__()
        self.model_name = model_name
        self.batch_size = batch_size
        self._model = None
        self._tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.torch_dtype = None

    @property
    def tokenizer(self) -> AutoTokenizer:
        if not self._tokenizer:
            self._tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        return self._tokenizer

    @property
    def model(self) -> AutoModelForSequenceClassification:
        if not self._model:
            print(f"'{self.model_name}' ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤. (Device: {self.device.upper()})")


            self.torch_dtype = torch.float32 # ê¸°ë³¸ê°’
            if "cuda" in self.device:
                # Ampere ì•„í‚¤í…ì²˜ ì´ìƒ (A100, RTX 30xx/40xx ë“±)ì¸ì§€ í™•ì¸
                if torch.cuda.get_device_capability(self.device)[0] >= 8:
                    self.torch_dtype = torch.bfloat16
                    print("bfloat16 ì§€ì› í™•ì¸. ëª¨ë¸ì„ bfloat16ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.")
                else:
                    self.torch_dtype = torch.float16
                    print("bfloat16 ë¯¸ì§€ì›. ëª¨ë¸ì„ float16 (AMP)ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.")

            print(f"'{self.model_name}' ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤. (Device: {self.device.upper()}, DType: {self.torch_dtype})")


            self._model = AutoModelForSequenceClassification.from_pretrained(
                self.model_name,
                torch_dtype=self.torch_dtype
            ).to(self.device)

            print(f"'{self.model_name}' ëª¨ë¸ ì»´íŒŒì¼ ì‹œì‘...")
            self._model = torch.compile(self._model)
            print(f"'{self.model_name}' ëª¨ë¸ ì»´íŒŒì¼ ì™„ë£Œ.")

        return self._model

    def run(self, data: DocumentsPipeline, rank: int = 0, world_size: int = 1) -> DocumentsPipeline:
        for batch in batched(data, self.batch_size):
            # ëª¨ë¸ ì…ë ¥ í˜•ì‹ì— ë§ê²Œ "passage: " ì ‘ë‘ì–´ ì¶”ê°€
            texts = ["passage: " + doc.text for doc in batch]

            try:
                with self.track_time("batch"), torch.no_grad():
                    # í…ìŠ¤íŠ¸ë¥¼ í† í¬ë‚˜ì´ì§•í•˜ê³  ëª¨ë¸ì´ ìˆëŠ” ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                    inputs = self.tokenizer(
                        texts,
                        return_tensors="pt",
                        padding=True,
                        truncation=True,
                        max_length=512
                    ).to(self.device)

                    # ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
                    outputs = self.model(**inputs)

                    # Logitsì—ì„œ ì§ì ‘ ì ìˆ˜ ì¶”ì¶œ (ì†Œí”„íŠ¸ë§¥ìŠ¤ ë¯¸ì ìš©)
                    # .squeeze(-1)ì„ í†µí•´ [batch_size, 1] -> [batch_size] í˜•íƒœë¡œ ë³€í™˜
                    scores = outputs.logits.squeeze(-1).float().cpu().numpy()

                for i, doc in enumerate(batch):
                    raw_score = scores[i].item() # numpy float -> python float ë³€í™˜

                    doc.metadata["edu_score_raw"] = round(raw_score, 4)
                    doc.metadata["edu_score"] = int(raw_score)

                    self.stat_update(f"score_{int(raw_score)}")

                yield from batch

            except Exception as e:
                self.stat_update("classification_error_batch")
                print(f"ë°°ì¹˜ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                for doc in batch:
                    doc.metadata["edu_score"] = -1
                    doc.metadata["edu_score_raw"] = -1.0
                    yield doc

# 2. ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•œ ì œë„ˆë ˆì´í„° í•¨ìˆ˜ (ìˆ˜ì •ë¨)
def load_multiple_sources(data: DocumentsPipeline, rank: int, world_size: int, paths: List[str]):
    """
    ì£¼ì–´ì§„ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë¡œë“œí•˜ëŠ” ì œë„ˆë ˆì´í„°ì…ë‹ˆë‹¤.
    datatrove íŒŒì´í”„ë¼ì¸ì˜ í‘œì¤€ ì¸ìë¥¼ ë°›ìŠµë‹ˆë‹¤.
    """
    # ì´ì „ ë‹¨ê³„ì˜ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ë¨¼ì € ì „ë‹¬í•©ë‹ˆë‹¤. (ì´ ê²½ìš° ì—†ìŒ)
    if data:
        yield from data

    for path in paths:
        print(f"--- Task {rank}/{world_size}: '{path}'ì—ì„œ ë°ì´í„° ë¡œë”© ì‹œì‘ ---")
        reader = ParquetReader(path, limit=4096) # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ limit ìœ ì§€
        # ê° ë¦¬ë”ì— rankì™€ world_sizeë¥¼ ì „ë‹¬í•˜ì—¬ ìƒ¤ë”©(sharding)ì´ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•˜ë„ë¡ í•©ë‹ˆë‹¤.
        yield from reader.run(rank=rank, world_size=world_size)


# -- íŒŒì´í”„ë¼ì¸ ì„¤ì • --

# huggingface-cli login ë˜ëŠ” login(token="...") í•„ìš”
# from huggingface_hub import login
# login("YOUR_HF_TOKEN")

# ìƒìˆ˜ ì •ì˜
TRAIN_DATASET_PATH = "hf://datasets/HuggingFaceFW/fineweb-2/data/kor_Hang/train"
TEST_DATASET_PATH = "hf://datasets/HuggingFaceFW/fineweb-2/data/kor_Hang/test"
TARGET_DATASET_NAME = "minpeter/fineweb-2-edu-korean-scored"
LOCAL_TEMP_DIR = "output/fineweb_korean_edu_scored_temp"

os.makedirs(LOCAL_TEMP_DIR, exist_ok=True)

# ì²˜ë¦¬í•  ë°ì´í„° ì†ŒìŠ¤ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
all_paths = [TRAIN_DATASET_PATH, TEST_DATASET_PATH]

# 3. functools.partialì„ ì‚¬ìš©í•˜ì—¬ í•¨ìˆ˜ì™€ ì¸ìë¥¼ ë¬¶ì–´ì¤ë‹ˆë‹¤.
loader = partial(load_multiple_sources, paths=all_paths)


if torch.cuda.is_available():
    num_tasks = torch.cuda.device_count()
    print(f"GPU ê°ì§€ë¨. {num_tasks}ê°œì˜ GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
else:
    num_tasks = os.cpu_count() or 1
    print(f"CPUë§Œ ì‚¬ìš©. {num_tasks}ê°œì˜ ì½”ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

executor = LocalPipelineExecutor(
    pipeline=[
        # 4. íŒŒì´í”„ë¼ì¸ì—ëŠ” í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼ê°€ ì•„ë‹Œ, partial ê°ì²´ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
        loader,
        EduScoreClassifier(batch_size=258),
        HuggingFaceDatasetWriter(
            dataset=TARGET_DATASET_NAME,
            local_working_dir=LOCAL_TEMP_DIR,
            private=False,
            output_filename="data/train-${rank}.parquet",
            cleanup=True,
        )
    ],
    tasks=num_tasks, # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì›í•œë‹¤ë©´ tasks > 1 ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
)

if __name__ == '__main__':
    print("--- train ë° test ë°ì´í„° í†µí•© ì²˜ë¦¬ ì‹œì‘ ---")
    executor.run()
    print("--- ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ ---")